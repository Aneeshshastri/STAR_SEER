{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":14480660,"sourceType":"datasetVersion","datasetId":9248920}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport glob\nimport h5py\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.saving import register_keras_serializable\nfrom tensorflow.keras import layers, models, Input, callbacks, regularizers\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\nfrom sklearn.linear_model import BayesianRidge\n\n#-----------------------\n#---configs so I don't have to search and change values at 10 different places in the script everytime I want to change smtg\n#---(lesson learnt the hard way)\n#-----------------------\nclass Config:\n    # --- Paths ---\n    H5_PATH = \"/kaggle/input/aspcapstar-dr17-150kstars/apogee_dr17_parallel.h5\" \n    TFREC_DIR = \"/kaggle/working/tfrecords\"\n    STATS_PATH = \"/kaggle/working/dataset_stats.npz\"\n    \n    # --- System ---\n    TESTING_MODE = True\n    TEST_LIMIT = 10000 \n    NUM_SHARDS = 16 \n    \n    # --- Model Hyperparameters ---\n    BATCH_SIZE = 512       \n    LEARNING_RATE = 2e-4   \n    EPOCHS = 50\n    LATENT_DIM = 268\n    OUTPUT_LENGTH = 8575\n    \n    # --loss related---\n    L2_VAL = 1e-4          \n    INPUT_NOISE = 0.05     \n    IVAR_SCALE = 1000.0   \n    CLIP_NORM = 1.0        \n\n    #----predictor-labels--------\n    SELECTED_LABELS = [\n        # 1. Core\n        'TEFF', 'LOGG', 'FE_H', 'VMICRO', 'VMACRO', 'VSINI',\n        # 2. CNO\n        'C_FE', 'N_FE', 'O_FE',\n        #3. metals\n        'MG_FE', 'SI_FE', 'CA_FE', 'TI_FE', 'S_FE',\n        'AL_FE', 'MN_FE', 'NI_FE', 'CR_FE' \n    ]\n\nconfig = Config()\nos.makedirs(config.TFREC_DIR, exist_ok=True)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-16T07:39:18.690133Z","iopub.execute_input":"2026-01-16T07:39:18.690869Z","iopub.status.idle":"2026-01-16T07:39:38.465011Z","shell.execute_reply.started":"2026-01-16T07:39:18.690840Z","shell.execute_reply":"2026-01-16T07:39:38.464217Z"}},"outputs":[{"name":"stderr","text":"2026-01-16 07:39:21.733764: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1768549162.085721      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1768549162.201582      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1768549163.030408      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768549163.030447      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768549163.030450      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768549163.030452      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"def get_nans(h5_path, selected_labels):\n    \"\"\"\n    Scans the dataset and prints the percentage of unusable (NaN/Flagged) \n    data for each label.\n    \"\"\"\n    print(f\"Scanning {len(selected_labels)} labels for missing data...\")\n    print(f\"{'LABEL':<10} | {'MISSING %':<10} | {'STATUS'}\")\n    \n    missing_report = {}\n    \n    with h5py.File(h5_path, 'r') as f:\n        # Detect structure (Group vs Table)\n        if isinstance(f['metadata'], h5py.Group):\n            get_col = lambda k: f['metadata'][k][:]\n            keys = list(f['metadata'].keys())\n        else:\n            get_col = lambda k: f['metadata'][k]\n            keys = f['metadata'].dtype.names\n\n        # Get total count from the first label\n        total_stars = len(get_col(selected_labels[0]))\n        \n        for label in selected_labels:\n            # 1. Get Raw Values\n            raw_vals = get_col(label)\n            \n            # 2. Check Flags (The Robust Logic)\n            flag_name = f\"{label}_FLAG\"\n            if flag_name in keys:\n                flg = get_col(flag_name)\n                # Handle Void/Structured types\n                if flg.dtype.names: flg = flg[flg.dtype.names[0]]\n                if flg.dtype.kind == 'V': flg = flg.view('<i4')\n                \n                # Bad if Flag != 0\n                is_bad_flag = (flg.astype(int) != 0)\n            else:\n                is_bad_flag = np.zeros(total_stars, dtype=bool)\n                \n            # 3. Check Placeholder Values (Standard APOGEE -9999)\n            # We check < -100 to catch any weird negative placeholders\n            is_bad_val = (raw_vals < -100)\n            \n            # 4. Combine (Either Flagged OR Missing Value)\n            total_bad = np.logical_or(is_bad_flag, is_bad_val)\n            \n            # 5. Calculate Stats\n            bad_count = np.sum(total_bad)\n            pct = (bad_count / total_stars) * 100\n            missing_report[label] = pct\n            \n            # 6. Status Indicator\n            if pct < 5.0:\n                status = \"Great\"\n            elif pct < 20.0:\n                status = \"Okay\"\n            else:\n                status = \"Hell Nah\"\n            \n            print(f\"{label:<10} | {pct:>9.2f}% | {status}\")\n\n    print(\"-\" * 50)\n    return missing_report\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-16T07:39:38.466345Z","iopub.execute_input":"2026-01-16T07:39:38.466952Z","iopub.status.idle":"2026-01-16T07:39:38.475295Z","shell.execute_reply.started":"2026-01-16T07:39:38.466927Z","shell.execute_reply":"2026-01-16T07:39:38.474550Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"#==================================\n\ndef get_clean_imputed_data(h5_path, selected_labels, limit=None):\n    \n    print(\"Read data for imputation\")\n    \n    with h5py.File(h5_path, 'r') as f:\n        # Detect structure type\n        if isinstance(f['metadata'], h5py.Group):\n            get_col = lambda k: f['metadata'][k][:]\n            keys = list(f['metadata'].keys())\n        else:\n            get_col = lambda k: f['metadata'][k]\n            keys = f['metadata'].dtype.names\n\n        raw_values = np.stack([get_col(p) for p in selected_labels], axis=1)\n        bad_mask = np.zeros_like(raw_values, dtype=bool)\n        \n        for i, label in enumerate(selected_labels):\n            flag_name = f\"{label}_FLAG\"\n            if flag_name in keys:\n                flg = get_col(flag_name)\n                # FIX: Handle Void/Structured Types safely\n                if flg.dtype.names: flg = flg[flg.dtype.names[0]]\n                if flg.dtype.kind == 'V': flg = flg.view('<i4')\n                is_bad = (flg.astype(int) != 0)\n            elif label in ['TEFF', 'LOGG', 'VMICRO', 'VMACRO', 'VSINI']:\n                is_bad = (raw_values[:, i] < -5000)\n            else:\n                is_bad = np.zeros_like(raw_values[:, i], dtype=bool)\n            bad_mask[:, i] = is_bad\n\n    if limit:\n        print(f\"âš ï¸ Truncating to first {limit} stars.\")\n        raw_values = raw_values[:limit]\n        bad_mask = bad_mask[:limit]\n\n    print(f\"   ðŸš€ Imputing Labels for {len(raw_values)} stars...\")\n    vals_to_impute = raw_values.copy()\n    vals_to_impute[bad_mask] = np.nan\n    \n    imputer = IterativeImputer(estimator=BayesianRidge(), max_iter=10, initial_strategy='median')\n    clean_labels = imputer.fit_transform(vals_to_impute)\n    return clean_labels\n\ndef _bytes_feature(value):\n    if isinstance(value, type(tf.constant(0))): value = value.numpy()\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\ndef generate_tfrecords():\n    \"\"\"Converts H5 to TFRecords (Runs once).\"\"\"\n    print(f\"ðŸš€ Starting TFRecord Generation (Shards: {config.NUM_SHARDS})...\")\n    limit = config.TEST_LIMIT if config.TESTING_MODE else None\n    \n    # 1. Clean Labels\n    clean_labels = get_clean_imputed_data(config.H5_PATH, config.SELECTED_LABELS, limit=limit)\n    \n    # 2. Save Stats\n    mean_labels = np.mean(clean_labels, axis=0)\n    std_labels = np.std(clean_labels, axis=0)\n    std_labels[std_labels == 0] = 1.0 \n    np.savez(config.STATS_PATH, mean=mean_labels, std=std_labels)\n    print(f\"âœ… Stats saved to {config.STATS_PATH}\")\n    \n    # 3. Write Shards\n    total_stars = len(clean_labels)\n    shard_size = int(np.ceil(total_stars / config.NUM_SHARDS))\n    \n    with h5py.File(config.H5_PATH, 'r') as f:\n        ds_flux = f['flux']\n        ds_ivar = f['ivar']\n        \n        for shard_id in range(config.NUM_SHARDS):\n            start_idx = shard_id * shard_size\n            end_idx = min((shard_id + 1) * shard_size, total_stars)\n            if start_idx >= total_stars: break\n            \n            filename = os.path.join(config.TFREC_DIR, f\"data_{shard_id:02d}.tfrec\")\n            print(f\"   Writing Shard {shard_id+1}/{config.NUM_SHARDS}: {filename}\")\n            \n            with tf.io.TFRecordWriter(filename) as writer:\n                chunk_flux = ds_flux[start_idx:end_idx]\n                chunk_ivar = ds_ivar[start_idx:end_idx]\n                chunk_labels = clean_labels[start_idx:end_idx]\n                \n                for i in range(len(chunk_labels)):\n                    label_bytes = tf.io.serialize_tensor(chunk_labels[i].astype(np.float32))\n                    spec_raw = np.stack([chunk_flux[i], chunk_ivar[i]], axis=-1).astype(np.float32)\n                    spec_bytes = tf.io.serialize_tensor(spec_raw)\n                    \n                    feature = {'labels': _bytes_feature(label_bytes), 'spectra': _bytes_feature(spec_bytes)}\n                    writer.write(tf.train.Example(features=tf.train.Features(feature=feature)).SerializeToString())\n    print(\"âœ… TFRecord Generation Complete.\")\n\n# Generate if missing\nif not glob.glob(os.path.join(config.TFREC_DIR, \"*.tfrec\")):\n    generate_tfrecords()\nelse:\n    print(\"âœ… TFRecords found. Skipping generation.\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-16T07:39:38.476180Z","iopub.execute_input":"2026-01-16T07:39:38.476445Z","iopub.status.idle":"2026-01-16T07:40:31.136758Z","shell.execute_reply.started":"2026-01-16T07:39:38.476416Z","shell.execute_reply":"2026-01-16T07:40:31.135943Z"}},"outputs":[{"name":"stdout","text":"ðŸš€ Starting TFRecord Generation (Shards: 16)...\nRead data for imputation\nâš ï¸ Truncating to first 10000 stars.\n   ðŸš€ Imputing Labels for 10000 stars...\nâœ… Stats saved to /kaggle/working/dataset_stats.npz\n   Writing Shard 1/16: /kaggle/working/tfrecords/data_00.tfrec\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1768549206.005089      55 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"},{"name":"stdout","text":"   Writing Shard 2/16: /kaggle/working/tfrecords/data_01.tfrec\n   Writing Shard 3/16: /kaggle/working/tfrecords/data_02.tfrec\n   Writing Shard 4/16: /kaggle/working/tfrecords/data_03.tfrec\n   Writing Shard 5/16: /kaggle/working/tfrecords/data_04.tfrec\n   Writing Shard 6/16: /kaggle/working/tfrecords/data_05.tfrec\n   Writing Shard 7/16: /kaggle/working/tfrecords/data_06.tfrec\n   Writing Shard 8/16: /kaggle/working/tfrecords/data_07.tfrec\n   Writing Shard 9/16: /kaggle/working/tfrecords/data_08.tfrec\n   Writing Shard 10/16: /kaggle/working/tfrecords/data_09.tfrec\n   Writing Shard 11/16: /kaggle/working/tfrecords/data_10.tfrec\n   Writing Shard 12/16: /kaggle/working/tfrecords/data_11.tfrec\n   Writing Shard 13/16: /kaggle/working/tfrecords/data_12.tfrec\n   Writing Shard 14/16: /kaggle/working/tfrecords/data_13.tfrec\n   Writing Shard 15/16: /kaggle/working/tfrecords/data_14.tfrec\n   Writing Shard 16/16: /kaggle/working/tfrecords/data_15.tfrec\nâœ… TFRecord Generation Complete.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Load Stats\nstats = np.load(config.STATS_PATH)\nMEAN_TENSOR = tf.constant(stats['mean'], dtype=tf.float32)\nSTD_TENSOR = tf.constant(stats['std'], dtype=tf.float32)\n\n# ==========================================\n \n# ==========================================\ndef parse_and_normalize(example_proto):\n    feature_desc = {\n        'labels': tf.io.FixedLenFeature([], tf.string),\n        'spectra': tf.io.FixedLenFeature([], tf.string),\n    }\n    parsed = tf.io.parse_single_example(example_proto, feature_desc)\n    labels = tf.io.parse_tensor(parsed['labels'], out_type=tf.float32)\n    spectra = tf.io.parse_tensor(parsed['spectra'], out_type=tf.float32)\n    \n    labels.set_shape([len(config.SELECTED_LABELS)])\n    spectra.set_shape([config.OUTPUT_LENGTH, 2])\n    \n    norm_labels = (labels - MEAN_TENSOR) / STD_TENSOR\n    return norm_labels, spectra\n\ndef build_dataset():\n    all_files = sorted(tf.io.gfile.glob(os.path.join(config.TFREC_DIR, \"*.tfrec\")))\n    split_idx = int(len(all_files) * 0.8)\n    if split_idx == len(all_files): split_idx -= 1\n    \n    train_files = all_files[:split_idx]\n    val_files = all_files[split_idx:]\n    print(f\"Data Split: {len(train_files)} Train Files, {len(val_files)} Val Files\")\n    \n    def load_files(filenames):\n        ds = tf.data.TFRecordDataset(filenames, num_parallel_reads=tf.data.AUTOTUNE)\n        ds = ds.map(parse_and_normalize, num_parallel_calls=tf.data.AUTOTUNE)\n        return ds\n    \n    train_ds = load_files(train_files).shuffle(10000).batch(config.BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n    val_ds = load_files(val_files).batch(config.BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n    return train_ds, val_ds\n\ntrain_ds, val_ds = build_dataset()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-16T07:40:31.138325Z","iopub.execute_input":"2026-01-16T07:40:31.138605Z","iopub.status.idle":"2026-01-16T07:40:31.253804Z","shell.execute_reply.started":"2026-01-16T07:40:31.138585Z","shell.execute_reply":"2026-01-16T07:40:31.253253Z"}},"outputs":[{"name":"stdout","text":"Data Split: 12 Train Files, 4 Val Files\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# ==========================================\n# Use a modiefied soblev loss function (I read in a paper it works well)\n# ==========================================\n\n@register_keras_serializable()\ndef sobolev_loss(y_true, y_pred):\n    real_flux = y_true[:, :, 0:1]\n    ivar = y_true[:, :, 1:2]\n    valid_mask = tf.cast(real_flux > -10.0, tf.float32)    \n    safe_flux = tf.where(valid_mask == 1.0, real_flux, y_pred)\n    ivar_safe = tf.clip_by_value(ivar / 1000.0, 0.0, 1.0)# scale and clip\n    ROI=tf.cast(tf.where(safe_flux<0.6,30,1),dtype=tf.float32) # weaker spectral lines\n    ROI2 =tf.cast(tf.where(safe_flux<0.3,5,1),dtype=tf.float32) #strong spectral lines\n    weight=tf.where(((safe_flux<0.7) & (ivar_safe>0)),tf.maximum(ivar_safe,tf.cast(0.1,dtype=tf.float32)),ivar_safe)\n    #chi2\n    mse_term = tf.square(safe_flux - y_pred) * weight * valid_mask*ROI*ROI2\n    \n    # calculate \"gradients\" (difference between adjacent pixels)\n    true_grad = safe_flux[:, 1:, :] - safe_flux[:, :-1, :]\n    pred_grad = y_pred[:, 1:, :] - y_pred[:, :-1, :]\n    \n    # Calculate Squared Error of gradients (sobolev loss term)\n    grad_sq_diff = tf.square(true_grad - pred_grad)\n    grad_mask = valid_mask[:, 1:, :] * valid_mask[:, :-1, :]\n    grad_trust = (weight[:, 1:, :] * weight[:, :-1, :])\n    # Apply mask to gradient loss\n    grad_loss = grad_sq_diff * grad_mask * grad_trust\n    \n    #pad last pixel\n    grad_loss = tf.pad(grad_loss, [[0,0], [0,1], [0,0]])\n    \n    # final loss\n    total_loss = (mse_term + (10.0 * grad_loss))\n    \n    #safety check\n    loss = tf.where(tf.math.is_finite(total_loss), total_loss, tf.zeros_like(total_loss))\n    \n    return tf.reduce_mean(loss)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-16T07:40:31.254663Z","iopub.execute_input":"2026-01-16T07:40:31.254934Z","iopub.status.idle":"2026-01-16T07:40:31.262344Z","shell.execute_reply.started":"2026-01-16T07:40:31.254902Z","shell.execute_reply":"2026-01-16T07:40:31.261908Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"#scaled the sigmoid function so my model can actually predict 1.0 and 0.0\n# most probably  there are better ways to do this, but I don't know any\n\n@register_keras_serializable()\ndef scaled_sigmoid(x):\n    return 1.3 * tf.nn.sigmoid(x)-0.15\n\n\ndef build_model():\n    input_dim = len(config.SELECTED_LABELS)\n    inputs = Input(shape=(input_dim,))\n    #Adding guassian noise just in case my model fits too well (:clown face:)\n    #x = layers.GaussianNoise(config.INPUT_NOISE)(inputs)\n    x=inputs\n    x = layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(config.L2_VAL))(x)\n    \n    #268*32 IS 8576 , very close to our output shape (8575)\n    x = layers.Dense(config.LATENT_DIM * 32, activation='relu',\\\n                     kernel_regularizer=regularizers.l2(config.L2_VAL))(x) # punish extreme weights\n    x = layers.Reshape((config.LATENT_DIM, 32))(x)\n    \n    #Progessively sharpen the image\n    filters = [64, 32, 32, 16, 16]\n    kernels = [7,  7,  5,  5,  3]\n\n    #residual blocks\n    for f, k in zip(filters, kernels):\n        x = layers.UpSampling1D(size=2)(x)\n        res = layers.Conv1D(f, 1, padding='same', kernel_regularizer=regularizers.l2(config.L2_VAL))(x)\n        x = layers.Conv1D(f, kernel_size=k, padding='same', kernel_regularizer=regularizers.l2(config.L2_VAL))(x)\n        x = layers.Activation('relu')(x)\n        x = layers.SpatialDropout1D(0.1)(x) #avoid overfitting\n        x = layers.Add()([x, res])\n\n    #final layer (crop the last pixel so output shape becomes 8575)\n    x = layers.Conv1D(1, kernel_size=3, padding='same', activation=scaled_sigmoid)(x)\n    outputs = layers.Cropping1D(cropping=(0, 1))(x)\n    \n    return models.Model(inputs, outputs, name=\"Spectrogram_Emulator\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-16T07:40:31.263308Z","iopub.execute_input":"2026-01-16T07:40:31.263783Z","iopub.status.idle":"2026-01-16T07:40:31.283084Z","shell.execute_reply.started":"2026-01-16T07:40:31.263753Z","shell.execute_reply":"2026-01-16T07:40:31.282375Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"#-----------------------\n#     TRAIN THE MODEL\n#-----------------------\nmodel = build_model()\nmodel.compile(optimizer=tf.keras.optimizers.Adam(config.LEARNING_RATE, clipnorm=config.CLIP_NORM), \n              loss=sobolev_loss)\n\ncallbacks_list = [\n    callbacks.ModelCheckpoint('best_emulator.keras', save_best_only=True, monitor='val_loss'),\n    callbacks.EarlyStopping(patience=3, restore_best_weights=True),\n    callbacks.ReduceLROnPlateau(patience=1, factor=0.5, min_lr=1e-6, verbose=1)\n]\n\nprint(\"BEGIN TRAINING\")\nhistory = model.fit(\n    train_ds,\n    validation_data=val_ds,\n    epochs=config.EPOCHS,\n    callbacks=callbacks_list,\n    verbose=1\n)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-16T07:40:31.284546Z","iopub.execute_input":"2026-01-16T07:40:31.284801Z"}},"outputs":[{"name":"stdout","text":"BEGIN TRAINING\nEpoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1768549238.292783     121 service.cc:152] XLA service 0x7faf44417050 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1768549238.292821     121 service.cc:160]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\nI0000 00:00:1768549239.654286     121 cuda_dnn.cc:529] Loaded cuDNN version 91002\n2026-01-16 07:40:54.763297: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng0{} for conv %cudnn-conv.41 = (f32[32,16,1,1]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,512,1,4288]{3,2,1,0} %bitcast.22334, f32[16,512,1,4288]{3,2,1,0} %bitcast.22343), window={size=1x4288}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", metadata={op_type=\"Conv2DBackpropFilter\" op_name=\"gradient_tape/Spectrogram_Emulator_1/conv1d_6_1/convolution/Conv2DBackpropFilter\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n2026-01-16 07:40:56.619355: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 2.856159138s\nTrying algorithm eng0{} for conv %cudnn-conv.41 = (f32[32,16,1,1]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,512,1,4288]{3,2,1,0} %bitcast.22334, f32[16,512,1,4288]{3,2,1,0} %bitcast.22343), window={size=1x4288}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", metadata={op_type=\"Conv2DBackpropFilter\" op_name=\"gradient_tape/Spectrogram_Emulator_1/conv1d_6_1/convolution/Conv2DBackpropFilter\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n2026-01-16 07:40:57.621529: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng1{k2=2,k3=0} for conv %cudnn-conv.42 = (f32[16,16,1,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,512,1,8576]{3,2,1,0} %bitcast.22527, f32[16,512,1,8576]{3,2,1,0} %bitcast.22534), window={size=1x8576 pad=0_0x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", metadata={op_type=\"Conv2DBackpropFilter\" op_name=\"gradient_tape/Spectrogram_Emulator_1/conv1d_9_1/convolution/Conv2DBackpropFilter\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n2026-01-16 07:41:00.191209: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 3.569771496s\nTrying algorithm eng1{k2=2,k3=0} for conv %cudnn-conv.42 = (f32[16,16,1,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,512,1,8576]{3,2,1,0} %bitcast.22527, f32[16,512,1,8576]{3,2,1,0} %bitcast.22534), window={size=1x8576 pad=0_0x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", metadata={op_type=\"Conv2DBackpropFilter\" op_name=\"gradient_tape/Spectrogram_Emulator_1/conv1d_9_1/convolution/Conv2DBackpropFilter\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n2026-01-16 07:41:01.191514: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng1{k2=4,k3=0} for conv %cudnn-conv.42 = (f32[16,16,1,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,512,1,8576]{3,2,1,0} %bitcast.22527, f32[16,512,1,8576]{3,2,1,0} %bitcast.22534), window={size=1x8576 pad=0_0x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", metadata={op_type=\"Conv2DBackpropFilter\" op_name=\"gradient_tape/Spectrogram_Emulator_1/conv1d_9_1/convolution/Conv2DBackpropFilter\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n2026-01-16 07:41:03.361933: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 3.170595793s\nTrying algorithm eng1{k2=4,k3=0} for conv %cudnn-conv.42 = (f32[16,16,1,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,512,1,8576]{3,2,1,0} %bitcast.22527, f32[16,512,1,8576]{3,2,1,0} %bitcast.22534), window={size=1x8576 pad=0_0x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", metadata={op_type=\"Conv2DBackpropFilter\" op_name=\"gradient_tape/Spectrogram_Emulator_1/conv1d_9_1/convolution/Conv2DBackpropFilter\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n2026-01-16 07:41:04.362178: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng2{k2=4,k3=0} for conv %cudnn-conv.42 = (f32[16,16,1,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,512,1,8576]{3,2,1,0} %bitcast.22527, f32[16,512,1,8576]{3,2,1,0} %bitcast.22534), window={size=1x8576 pad=0_0x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", metadata={op_type=\"Conv2DBackpropFilter\" op_name=\"gradient_tape/Spectrogram_Emulator_1/conv1d_9_1/convolution/Conv2DBackpropFilter\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n2026-01-16 07:41:04.575699: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.213618604s\nTrying algorithm eng2{k2=4,k3=0} for conv %cudnn-conv.42 = (f32[16,16,1,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,512,1,8576]{3,2,1,0} %bitcast.22527, f32[16,512,1,8576]{3,2,1,0} %bitcast.22534), window={size=1x8576 pad=0_0x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", metadata={op_type=\"Conv2DBackpropFilter\" op_name=\"gradient_tape/Spectrogram_Emulator_1/conv1d_9_1/convolution/Conv2DBackpropFilter\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n2026-01-16 07:41:06.561432: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng28{k2=4,k3=0} for conv %cudnn-conv.42 = (f32[16,16,1,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,512,1,8576]{3,2,1,0} %bitcast.22527, f32[16,512,1,8576]{3,2,1,0} %bitcast.22534), window={size=1x8576 pad=0_0x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", metadata={op_type=\"Conv2DBackpropFilter\" op_name=\"gradient_tape/Spectrogram_Emulator_1/conv1d_9_1/convolution/Conv2DBackpropFilter\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n2026-01-16 07:41:06.726400: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.165084113s\nTrying algorithm eng28{k2=4,k3=0} for conv %cudnn-conv.42 = (f32[16,16,1,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,512,1,8576]{3,2,1,0} %bitcast.22527, f32[16,512,1,8576]{3,2,1,0} %bitcast.22534), window={size=1x8576 pad=0_0x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", metadata={op_type=\"Conv2DBackpropFilter\" op_name=\"gradient_tape/Spectrogram_Emulator_1/conv1d_9_1/convolution/Conv2DBackpropFilter\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n2026-01-16 07:41:07.726619: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng0{} for conv %cudnn-conv.42 = (f32[16,16,1,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,512,1,8576]{3,2,1,0} %bitcast.22527, f32[16,512,1,8576]{3,2,1,0} %bitcast.22534), window={size=1x8576 pad=0_0x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", metadata={op_type=\"Conv2DBackpropFilter\" op_name=\"gradient_tape/Spectrogram_Emulator_1/conv1d_9_1/convolution/Conv2DBackpropFilter\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n2026-01-16 07:41:11.838931: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 5.112400635s\nTrying algorithm eng0{} for conv %cudnn-conv.42 = (f32[16,16,1,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,512,1,8576]{3,2,1,0} %bitcast.22527, f32[16,512,1,8576]{3,2,1,0} %bitcast.22534), window={size=1x8576 pad=0_0x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", metadata={op_type=\"Conv2DBackpropFilter\" op_name=\"gradient_tape/Spectrogram_Emulator_1/conv1d_9_1/convolution/Conv2DBackpropFilter\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n2026-01-16 07:41:12.841160: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng1{k2=2,k3=0} for conv %cudnn-conv.43 = (f32[16,16,1,1]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,512,1,8576]{3,2,1,0} %bitcast.22527, f32[16,512,1,8576]{3,2,1,0} %bitcast.22738), window={size=1x8576}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", metadata={op_type=\"Conv2DBackpropFilter\" op_name=\"gradient_tape/Spectrogram_Emulator_1/conv1d_8_1/convolution/Conv2DBackpropFilter\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n2026-01-16 07:41:13.644899: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.803833621s\nTrying algorithm eng1{k2=2,k3=0} for conv %cudnn-conv.43 = (f32[16,16,1,1]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,512,1,8576]{3,2,1,0} %bitcast.22527, f32[16,512,1,8576]{3,2,1,0} %bitcast.22738), window={size=1x8576}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", metadata={op_type=\"Conv2DBackpropFilter\" op_name=\"gradient_tape/Spectrogram_Emulator_1/conv1d_8_1/convolution/Conv2DBackpropFilter\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n2026-01-16 07:41:14.645111: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng1{k2=4,k3=0} for conv %cudnn-conv.43 = (f32[16,16,1,1]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,512,1,8576]{3,2,1,0} %bitcast.22527, f32[16,512,1,8576]{3,2,1,0} %bitcast.22738), window={size=1x8576}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", metadata={op_type=\"Conv2DBackpropFilter\" op_name=\"gradient_tape/Spectrogram_Emulator_1/conv1d_8_1/convolution/Conv2DBackpropFilter\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n2026-01-16 07:41:15.008431: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.363412026s\nTrying algorithm eng1{k2=4,k3=0} for conv %cudnn-conv.43 = (f32[16,16,1,1]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,512,1,8576]{3,2,1,0} %bitcast.22527, f32[16,512,1,8576]{3,2,1,0} %bitcast.22738), window={size=1x8576}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", metadata={op_type=\"Conv2DBackpropFilter\" op_name=\"gradient_tape/Spectrogram_Emulator_1/conv1d_8_1/convolution/Conv2DBackpropFilter\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n2026-01-16 07:41:16.008732: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng2{k2=4,k3=0} for conv %cudnn-conv.43 = (f32[16,16,1,1]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,512,1,8576]{3,2,1,0} %bitcast.22527, f32[16,512,1,8576]{3,2,1,0} %bitcast.22738), window={size=1x8576}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", metadata={op_type=\"Conv2DBackpropFilter\" op_name=\"gradient_tape/Spectrogram_Emulator_1/conv1d_8_1/convolution/Conv2DBackpropFilter\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n2026-01-16 07:41:16.195376: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.186820794s\nTrying algorithm eng2{k2=4,k3=0} for conv %cudnn-conv.43 = (f32[16,16,1,1]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,512,1,8576]{3,2,1,0} %bitcast.22527, f32[16,512,1,8576]{3,2,1,0} %bitcast.22738), window={size=1x8576}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", metadata={op_type=\"Conv2DBackpropFilter\" op_name=\"gradient_tape/Spectrogram_Emulator_1/conv1d_8_1/convolution/Conv2DBackpropFilter\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n2026-01-16 07:41:18.141775: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng28{k2=4,k3=0} for conv %cudnn-conv.43 = (f32[16,16,1,1]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,512,1,8576]{3,2,1,0} %bitcast.22527, f32[16,512,1,8576]{3,2,1,0} %bitcast.22738), window={size=1x8576}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", metadata={op_type=\"Conv2DBackpropFilter\" op_name=\"gradient_tape/Spectrogram_Emulator_1/conv1d_8_1/convolution/Conv2DBackpropFilter\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n2026-01-16 07:41:18.371155: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.229478594s\nTrying algorithm eng28{k2=4,k3=0} for conv %cudnn-conv.43 = (f32[16,16,1,1]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,512,1,8576]{3,2,1,0} %bitcast.22527, f32[16,512,1,8576]{3,2,1,0} %bitcast.22738), window={size=1x8576}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", metadata={op_type=\"Conv2DBackpropFilter\" op_name=\"gradient_tape/Spectrogram_Emulator_1/conv1d_8_1/convolution/Conv2DBackpropFilter\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n2026-01-16 07:41:19.371338: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng0{} for conv %cudnn-conv.43 = (f32[16,16,1,1]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,512,1,8576]{3,2,1,0} %bitcast.22527, f32[16,512,1,8576]{3,2,1,0} %bitcast.22738), window={size=1x8576}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", metadata={op_type=\"Conv2DBackpropFilter\" op_name=\"gradient_tape/Spectrogram_Emulator_1/conv1d_8_1/convolution/Conv2DBackpropFilter\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n2026-01-16 07:41:21.544078: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 3.172823337s\nTrying algorithm eng0{} for conv %cudnn-conv.43 = (f32[16,16,1,1]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,512,1,8576]{3,2,1,0} %bitcast.22527, f32[16,512,1,8576]{3,2,1,0} %bitcast.22738), window={size=1x8576}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", metadata={op_type=\"Conv2DBackpropFilter\" op_name=\"gradient_tape/Spectrogram_Emulator_1/conv1d_8_1/convolution/Conv2DBackpropFilter\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\nI0000 00:00:1768549286.388632     121 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"     14/Unknown \u001b[1m68s\u001b[0m 1s/step - loss: 0.3163","output_type":"stream"},{"name":"stderr","text":"2026-01-16 07:41:52.130182: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng0{} for conv %cudnn-conv.41 = (f32[32,16,1,1]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,332,1,4288]{3,2,1,0} %bitcast.22334, f32[16,332,1,4288]{3,2,1,0} %bitcast.22343), window={size=1x4288}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", metadata={op_type=\"Conv2DBackpropFilter\" op_name=\"gradient_tape/Spectrogram_Emulator_1/conv1d_6_1/convolution/Conv2DBackpropFilter\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n2026-01-16 07:41:52.982618: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.852557426s\nTrying algorithm eng0{} for conv %cudnn-conv.41 = (f32[32,16,1,1]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,332,1,4288]{3,2,1,0} %bitcast.22334, f32[16,332,1,4288]{3,2,1,0} %bitcast.22343), window={size=1x4288}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", metadata={op_type=\"Conv2DBackpropFilter\" op_name=\"gradient_tape/Spectrogram_Emulator_1/conv1d_6_1/convolution/Conv2DBackpropFilter\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"\n#----SAVE AND PREDICT-----\n\nimport matplotlib.pyplot as plt\n\nmodel=tf.keras.models.load_model('best_emulator.keras')\nmodel.save('SPECTROGRAM_GENERATOR.keras')\n\n\n\ndef plot_spectrum_comparison(y_true, y_pred,ivar=None, labels=None, title=\"Stellar Reconstruction\"):\n    plt.style.use('dark_background') #dark mode >>>>>> \n    wavelengths=np.logspace(np.log10(1514),np.log10(1695),config.OUTPUT_LENGTH)\n    # APOGEE takes log wavelengths to space their pixels\n    fig, (ax1, ax2, ax3) = plt.subplots(\n        3, 1, figsize=(14, 8), \n        gridspec_kw={'height_ratios': [3, 1,2]}, \n        sharex=True\n    )\n    \n    \n    #TOP= SPECTROGRAMS   \n    ax1.plot(wavelengths, y_true, color='red', alpha=0.8, linewidth=1, label='Ground Truth (APOGEE)')\n    ax1.plot(wavelengths, y_pred, color='cyan', alpha=0.9, linewidth=0.8, label='Emulator Prediction')\n    ax1.set_ylabel(\"Flux\", fontsize=12, color='white')\n    ax1.set_title(title, fontsize=16, fontweight='bold', color='white')\n    ax1.legend(frameon=False, fontsize=12)\n\n    \n    #Strong spectral lines that can be seen in stars collected from APOGEE\n    # AI generated, couldn't bother looking it up myself (I'll do it later)\n    lines = [\n        # --- Iron Peak & Core Elements ---\n        (1519, \"Fe\"),     # Strong Iron anchor\n        (1526, \"Mn\"),     # Manganese (Deep Line Driver)\n        (1539, \"Fe\"),     # Strong Iron\n        (1569, \"Fe/Ti\"),  # Strong blend\n        (1576, \"Mg\"),     # Magnesium Triplet Center (The \"Big One\")\n        (1605, \"Ni\"),     # Nickel (Deep Line Driver)\n        (1615, \"Ca/Fe\"),  # Calcium & Iron\n        (1667, \"Ni\"),     # Nickel\n        (1682, \"Ni\"),     # Nickel\n\n        # --- Alpha Elements ---\n        (1596, \"Si\"),     # Silicon (Very distinctive dip)\n        (1638, \"Si\"),     # Silicon\n        (1672, \"Al\"),     # Aluminum (The \"Deepest\" single line usually)\n\n        # --- Molecular Bandheads (The \"Continuum Shapers\") ---\n        (1533, \"CN\"),     # Cyanogen band\n        (1558, \"CO\"),     # Carbon Monoxide Bandhead (Start of 'sawtooth')\n        (1619, \"CO\"),     # CO Bandhead\n        (1661, \"CO\"), \n        (1675, \"Al\"),# CO Bandhead (Very strong in cool stars)\n    ]\n    \n    for wl, name in lines:\n        ax1.axvline(x=wl, color='magenta', alpha=0.3, linestyle='--')\n        ax1.text(wl, 1.15, name, color='magenta', rotation=90, fontsize=10)\n        \n    #BOTTOM=RESIDUALS\n    #compare how well the model fits the data\n    residuals = y_true - y_pred\n    ax2.plot(wavelengths, residuals, color='#FF5555', linewidth=0.8)\n    ax2.axhline(0, color='white', linestyle='--', alpha=0.5)\n    ax2.set_ylabel(\"Residuals\\n(True - Pred)\", fontsize=10)\n    \n    \n    for wl, name in lines:\n        ax2.axvline(x=wl, color='magenta', alpha=0.3, linestyle='--')\n        ax2.text(wl, 1.15, name, color='magenta', rotation=90, fontsize=10)\n    #ax2.set_ylim(-0.2, 0.2) => hopefully my model fits good enough for me to do this (it didn't ;-;)\n    \n    # show imp labels\n    if labels is not None:\n        info_str = f\"Teff: {labels[0]} K\\nLogg: {labels[1]:.2f}\\n[Fe/H]: {labels[2]:.2f}\"\n        ax1.text(0.02, 0.1, info_str, transform=ax1.transAxes, \n                 bbox=dict(facecolor='grey', alpha=0.8, edgecolor='gray'),\n                 fontsize=11, color='white')\n    ax3.plot(wavelengths,np.log(ivar)-10,color='red',linewidth=0.8)\n    ax3.set_ylabel(\"log(inverse variance)\",fontsize=10)\n    ax3.set_xlabel(\"Wavelength (in nm)\", fontsize=12)\n    \n    fig.tight_layout() \n    fig.savefig(\"/kaggle/working/spectrogram_1.jpg\")\n    fig.show()\n\n#generate sample spectrograms\nfor batch_labels, batch_spectra in val_ds.take(1):\n   \n    preds = model.predict(batch_labels)\n\n    idx = 0\n    true_spec = batch_spectra[idx, :, 0] \n    ivar=batch_spectra[idx,:,1]\n    pred_spec = preds[idx, :, 0]\n    star_labels = batch_labels[idx]\n    star_labels=star_labels*STD_TENSOR+MEAN_TENSOR\n    plot_spectrum_comparison(true_spec, pred_spec,ivar, labels=star_labels)\n    break","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}